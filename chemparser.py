# ----------------------------------------------------------------------------
# Copyright 2021, QIIME 2 development team.
#
# Distributed under the terms of the Modified BSD License.
#
# The full license is in the file LICENSE, distributed with this software.
# ----------------------------------------------------------------------------


import re, os
import pandas as pd
import numpy as np
from enum import Enum


class StateMachine(Enum):
    "A state machine for the parsing of the initial file into sections."
    LEADING_HEADER = 0
    TITLE = 1
    CLOSING_HEADER = 2
    CONTENT = 3
    NEWSECT = 4

class AnalyzerMachine(Enum):
    "A state machine for parsing the data section into a dataframe."
    STEP_BEGIN = 0
    STEP_CONTENTS = 1
    STEP_END = 2

HEADER_LINE = '-'*80


def parse_out(outfile):
    "A parser for .out files generated by amber pmemd MD simulations."
    
    # state machine variable
    state_machine = StateMachine.LEADING_HEADER

    # First opening the file and seperating by row
    with open(outfile, "r") as fh:
        
        sections = []
        contents = []
        
        # State Machine to identify sections and create respective DataFrames
        for line in fh:
            line = line.strip()
            if state_machine == StateMachine.LEADING_HEADER:
                if line == HEADER_LINE:
                    state_machine = StateMachine.TITLE
                    continue
            if state_machine == StateMachine.TITLE:
                if re.match("^\d.", line):
                    sections.append(line)
                    state_machine = StateMachine.CLOSING_HEADER
                    continue
            # new section starts if it reaches here
            if state_machine == StateMachine.CLOSING_HEADER:
                if line == HEADER_LINE:
                    state_machine = StateMachine.CONTENT
                    contents.append([])
                    continue
            if state_machine == StateMachine.CONTENT:
                if line == HEADER_LINE:
                    state_machine = StateMachine.NEWSECT
                    continue
                else:
                    contents[-1].append(line)
            if state_machine == StateMachine.NEWSECT:
                if re.match("^\d.", line):
                    sections.append(line)
                    state_machine = StateMachine.CLOSING_HEADER
                    continue
                else:
                    state_machine = StateMachine.CONTENT
                    continue
        # Puts section titles and their body's into key pairs in a dictionary
        compartments = {}
        for x in zip(sections, contents):
            compartments[x[0]] = x[1]
        
        # grabs the results section with the important data from the dictionary and returns that
        return compartments['4.  RESULTS'][17:]
        
# Function to transform parsed .out file into a dataframe
def transform_parse(results_section):
    "A function to analyze the data section of the parsed file"
    # Turning results section from a list to a string 
    result_str = ""
    for line in results_section:
        result_str += line

    # match test for parser to match result's body against.
    # 3 capture groups are present, so matches are recorded in tuples holding 3 values
    matchtest = re.compile('((\d\-\d\s)?[\w\(\)]+)\s*\=\s*(\-?\d+.\d*)')
    parsed_tuples = matchtest.findall(result_str)

    # Dictionary to hold data key pairings
    data_dict = {}
    # Parse the matched tuples into a list of tuples
    parsed_tup_list = list(parsed_tuples)

    # Iterate over the tuple list and place into data dictionary by keyword
    for i in range(len(parsed_tup_list)):
        # If keyword already in dictionary add the value to list paired to that keyword
        if parsed_tup_list[i][0] in data_dict:
            data_dict[parsed_tup_list[i][0]].append(parsed_tup_list[i][2])
        # Else if keyword isn't present in dictionary, add it and pair the data with it
        else:
            data_dict[parsed_tup_list[i][0]]= []
            data_dict[parsed_tup_list[i][0]].append(parsed_tup_list[i][2])
    
    # Creating a DataFrame from this dictionary
    fdf = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in data_dict.items() ]))
    
    # Fixing last two rows showing Averages and Fluctuations, and removing the extra row with NaN values
    fdf = fdf[:-2]
    fdf = fdf.drop(columns=['SNSTEP'])

    # Returning the final dataframe
    return fdf

# Pipeline function to parse and transform .out files into dataframes
def parse_pl(outfile):
    results = parse_out(outfile)
    df = transform_parse(results)
    df = df.astype(float)

    return df
